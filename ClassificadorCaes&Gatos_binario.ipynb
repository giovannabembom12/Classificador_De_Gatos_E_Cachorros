{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BAfAMGlRZgR",
        "outputId": "1abef381-f675-4547-dea4-5d1b7d858cb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ltn in /usr/local/lib/python3.12/dist-packages (2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ltn) (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (from ltn) (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->ltn) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow->ltn) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->ltn) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->ltn) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->ltn) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->ltn) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->ltn) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->ltn) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->ltn) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->ltn) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->ltn) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->ltn) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow->ltn) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->ltn) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->ltn) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->ltn) (0.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Classificador Bin√°rio de C√£es e Gatos usando Logic Tensor Networks (LTN)\n",
        "Dataset: Microsoft Cats vs Dogs (Hugging Face)\n",
        "\"\"\"\n",
        "\n",
        "# Instala√ß√£o de depend√™ncias\n",
        "!pip install ltn\n",
        "!pip install torch torchvision\n",
        "!pip install datasets transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Usado\n",
        "disponivel em: https://www.microsoft.com/en-us/download/details.aspx?id=54765\n"
      ],
      "metadata": {
        "id": "pyW7BiZB8uif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# montar no drive e carregar as variaveis path"
      ],
      "metadata": {
        "id": "aogPb-3V7ktn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "pathcat = '/content/drive/MyDrive/DatasetCaes&Gatos/cats'\n",
        "pathdog = '/content/drive/MyDrive/DatasetCaes&Gatos/dogs'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1Tm-f9J_Cm8",
        "outputId": "bc19c5d5-474c-4d76-e3c4-3a78bbba8380"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeCEpMLcPeGq",
        "outputId": "8bf2bce1-2f93-4ec9-f796-dde3b9435c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CLASSIFICADOR BIN√ÅRIO: C√ÉES vs GATOS (DATASET LOCAL)\n",
            "Usando BCEWithLogits + L√≥gica fuzzy (LTN simplificada)\n",
            "============================================================\n",
            "\n",
            "üìÇ Pasta de c√£es: /content/drive/MyDrive/DatasetCaes&Gatos/dogs\n",
            "üìÇ Pasta de gatos: /content/drive/MyDrive/DatasetCaes&Gatos/cats\n",
            "\n",
            "üñ•Ô∏è  Usando device: cuda\n",
            "\n",
            "============================================================\n",
            "ETAPA 1: Carregando Dataset\n",
            "============================================================\n",
            "üì• Carregando imagens das pastas locais...\n",
            "‚úì C√£es encontrados: 500\n",
            "‚úì Gatos encontrados: 500\n",
            "‚úì Pares balanceados: 500\n",
            "‚úì DataLoader criado com 8 batches\n",
            "\n",
            "============================================================\n",
            "ETAPA 2: Criando Modelo CNN\n",
            "============================================================\n",
            "‚úì Modelo criado com 10980673 par√¢metros\n",
            "\n",
            "============================================================\n",
            "ETAPA 3: Iniciando Treinamento\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [5/8], Loss: 0.7140, Acc(batch): 50.00%\n",
            "rodando...\n",
            "Epoch [1/5], Step [8/8], Loss: 0.7558, Acc(batch): 50.30%\n",
            "\n",
            "============================================================\n",
            "Epoch [1/5] Completado\n",
            "Loss M√©dio: 1.0817\n",
            "Acur√°cia: 50.30%\n",
            "C√£es corretos (aprx): 342/500\n",
            "Gatos corretos (aprx): 161/500\n",
            "============================================================\n",
            "\n",
            "üíæ Novo melhor modelo (na mem√≥ria). Loss: 1.0817\n",
            "\n",
            "Epoch [2/5], Step [5/8], Loss: 0.7748, Acc(batch): 50.94%\n",
            "rodando...\n",
            "Epoch [2/5], Step [8/8], Loss: 0.7303, Acc(batch): 50.90%\n",
            "\n",
            "============================================================\n",
            "Epoch [2/5] Completado\n",
            "Loss M√©dio: 0.7499\n",
            "Acur√°cia: 50.90%\n",
            "C√£es corretos (aprx): 354/500\n",
            "Gatos corretos (aprx): 155/500\n",
            "============================================================\n",
            "\n",
            "üíæ Novo melhor modelo (na mem√≥ria). Loss: 0.7499\n",
            "\n",
            "Epoch [3/5], Step [5/8], Loss: 0.6840, Acc(batch): 51.88%\n",
            "rodando...\n",
            "Epoch [3/5], Step [8/8], Loss: 0.6531, Acc(batch): 52.70%\n",
            "\n",
            "============================================================\n",
            "Epoch [3/5] Completado\n",
            "Loss M√©dio: 0.6912\n",
            "Acur√°cia: 52.70%\n",
            "C√£es corretos (aprx): 385/500\n",
            "Gatos corretos (aprx): 142/500\n",
            "============================================================\n",
            "\n",
            "üíæ Novo melhor modelo (na mem√≥ria). Loss: 0.6912\n",
            "\n",
            "rodando...\n",
            "Epoch [4/5], Step [5/8], Loss: 0.6478, Acc(batch): 53.59%\n",
            "Epoch [4/5], Step [8/8], Loss: 0.6511, Acc(batch): 55.80%\n",
            "\n",
            "============================================================\n",
            "Epoch [4/5] Completado\n",
            "Loss M√©dio: 0.6621\n",
            "Acur√°cia: 55.80%\n",
            "C√£es corretos (aprx): 436/500\n",
            "Gatos corretos (aprx): 122/500\n",
            "============================================================\n",
            "\n",
            "üíæ Novo melhor modelo (na mem√≥ria). Loss: 0.6621\n",
            "\n",
            "Epoch [5/5], Step [5/8], Loss: 0.6016, Acc(batch): 62.50%\n",
            "rodando...\n",
            "Epoch [5/5], Step [8/8], Loss: 0.6936, Acc(batch): 61.40%\n",
            "\n",
            "============================================================\n",
            "Epoch [5/5] Completado\n",
            "Loss M√©dio: 0.6498\n",
            "Acur√°cia: 61.40%\n",
            "C√£es corretos (aprx): 383/500\n",
            "Gatos corretos (aprx): 231/500\n",
            "============================================================\n",
            "\n",
            "üíæ Novo melhor modelo (na mem√≥ria). Loss: 0.6498\n",
            "\n",
            "üéâ Treinamento conclu√≠do!\n",
            "\n",
            "============================================================\n",
            "AVALIA√á√ÉO DO MODELO\n",
            "============================================================\n",
            "\n",
            "Predi√ß√µes para 5 imagens de C√ÉES:\n",
            "  Imagem 1: 0.8388 (esperado: ~1.0)\n",
            "  Imagem 2: 0.3957 (esperado: ~1.0)\n",
            "  Imagem 3: 0.5670 (esperado: ~1.0)\n",
            "  Imagem 4: 0.7479 (esperado: ~1.0)\n",
            "  Imagem 5: 0.1336 (esperado: ~1.0)\n",
            "\n",
            "Predi√ß√µes para 5 imagens de GATOS:\n",
            "  Imagem 1: 0.4821 (esperado: ~0.0)\n",
            "  Imagem 2: 0.2700 (esperado: ~0.0)\n",
            "  Imagem 3: 0.3264 (esperado: ~0.0)\n",
            "  Imagem 4: 0.1697 (esperado: ~0.0)\n",
            "  Imagem 5: 0.1832 (esperado: ~0.0)\n",
            "\n",
            "‚úì Acur√°cia nas amostras: 80.00%\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# ======= Configura√ß√£o dos caminhos do dataset =======\n",
        "pathcat = '/content/drive/MyDrive/DatasetCaes&Gatos/cats'\n",
        "pathdog = '/content/drive/MyDrive/DatasetCaes&Gatos/dogs'\n",
        "\n",
        "# ======= Semente para reprodutibilidade =======\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# =====================================================================\n",
        "# 1. DATASET E DATALOADER (MODIFICADO PARA PASTAS LOCAIS)\n",
        "# =====================================================================\n",
        "\n",
        "class LocalDogCatDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset usando pastas locais 'dogs' e 'cats'\n",
        "    Retorna pares (dog_img, cat_img) como no c√≥digo original.\n",
        "    \"\"\"\n",
        "    def __init__(self, dogs_dir='dogs', cats_dir='cats', transform=None, max_samples=None):\n",
        "        print(\"üì• Carregando imagens das pastas locais...\")\n",
        "\n",
        "        # Convertendo para Path objects\n",
        "        self.dogs_dir = Path(dogs_dir)\n",
        "        self.cats_dir = Path(cats_dir)\n",
        "\n",
        "        # Verificar se os diret√≥rios existem\n",
        "        if not self.dogs_dir.exists():\n",
        "            raise ValueError(f\"‚ùå Diret√≥rio de c√£es n√£o encontrado: {dogs_dir}\")\n",
        "        if not self.cats_dir.exists():\n",
        "            raise ValueError(f\"‚ùå Diret√≥rio de gatos n√£o encontrado: {cats_dir}\")\n",
        "\n",
        "        # Extens√µes de imagem suportadas\n",
        "        valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp'}\n",
        "\n",
        "        # Carregar caminhos das imagens de c√£es\n",
        "        self.dog_images = [\n",
        "            str(f) for f in self.dogs_dir.iterdir()\n",
        "            if f.is_file() and f.suffix.lower() in valid_extensions\n",
        "        ]\n",
        "\n",
        "        # Carregar caminhos das imagens de gatos\n",
        "        self.cat_images = [\n",
        "            str(f) for f in self.cats_dir.iterdir()\n",
        "            if f.is_file() and f.suffix.lower() in valid_extensions\n",
        "        ]\n",
        "\n",
        "        # Embaralhar para aleatoriedade\n",
        "        random.shuffle(self.dog_images)\n",
        "        random.shuffle(self.cat_images)\n",
        "\n",
        "        # Limitar n√∫mero de amostras se especificado\n",
        "        if max_samples is not None and max_samples > 0:\n",
        "            self.dog_images = self.dog_images[:max_samples]\n",
        "            self.cat_images = self.cat_images[:max_samples]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "        print(f\"‚úì C√£es encontrados: {len(self.dog_images)}\")\n",
        "        print(f\"‚úì Gatos encontrados: {len(self.cat_images)}\")\n",
        "        print(f\"‚úì Pares balanceados: {min(len(self.dog_images), len(self.cat_images))}\")\n",
        "\n",
        "        if len(self.dog_images) == 0 or len(self.cat_images) == 0:\n",
        "            raise ValueError(\"‚ùå Erro: N√£o foram encontradas imagens suficientes de c√£es ou gatos!\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.dog_images), len(self.cat_images))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Carregar imagens com retry autom√°tico em caso de erro\n",
        "        max_retries = 10\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                # Ajustar √≠ndice se necess√°rio\n",
        "                dog_idx = (idx + attempt) % len(self.dog_images)\n",
        "                cat_idx = (idx + attempt) % len(self.cat_images)\n",
        "\n",
        "                dog_path = self.dog_images[dog_idx]\n",
        "                cat_path = self.cat_images[cat_idx]\n",
        "\n",
        "                # Tentar carregar imagem de c√£o\n",
        "                dog_img = Image.open(dog_path).convert('RGB')\n",
        "                # Verificar se a imagem √© v√°lida tentando carreg√°-la\n",
        "                dog_img.load()\n",
        "\n",
        "                # Tentar carregar imagem de gato\n",
        "                cat_img = Image.open(cat_path).convert('RGB')\n",
        "                # Verificar se a imagem √© v√°lida tentando carreg√°-la\n",
        "                cat_img.load()\n",
        "\n",
        "                # Aplicar transforma√ß√µes\n",
        "                if self.transform:\n",
        "                    dog_img = self.transform(dog_img)\n",
        "                    cat_img = self.transform(cat_img)\n",
        "\n",
        "                return dog_img, cat_img\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt == 0:  # S√≥ printa no primeiro erro\n",
        "                    print(\"rodando...\")\n",
        "                continue\n",
        "\n",
        "        # Se todas as tentativas falharem, retorna imagens em branco\n",
        "        print(f\"‚ùå N√£o foi poss√≠vel carregar imagens v√°lidas ap√≥s {max_retries} tentativas\")\n",
        "        dog_img = torch.randn(3, 96, 96)  # imagem aleat√≥ria\n",
        "        cat_img = torch.randn(3, 96, 96)\n",
        "        return dog_img, cat_img\n",
        "\n",
        "\n",
        "def get_transforms(image_size=128, augmentation=True):\n",
        "    \"\"\"Define transforma√ß√µes para as imagens (um pouco menos agressivas)\"\"\"\n",
        "    if augmentation:\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((image_size, image_size)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomRotation(8),\n",
        "            transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    else:\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((image_size, image_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "\n",
        "def create_dataloader(dogs_dir='dogs', cats_dir='cats', batch_size=16,\n",
        "                      image_size=128, num_workers=0, augmentation=True, max_samples=None):\n",
        "    \"\"\"\n",
        "    Cria DataLoader a partir de pastas locais\n",
        "\n",
        "    Args:\n",
        "        dogs_dir: caminho para pasta com imagens de c√£es\n",
        "        cats_dir: caminho para pasta com imagens de gatos\n",
        "        batch_size: tamanho do batch\n",
        "        image_size: tamanho das imagens (redimensionadas)\n",
        "        num_workers: n√∫mero de workers para carregamento\n",
        "        augmentation: aplicar data augmentation\n",
        "        max_samples: n√∫mero m√°ximo de amostras por classe\n",
        "    \"\"\"\n",
        "    transform = get_transforms(image_size, augmentation)\n",
        "    dataset = LocalDogCatDataset(\n",
        "        dogs_dir=dogs_dir,\n",
        "        cats_dir=cats_dir,\n",
        "        transform=transform,\n",
        "        max_samples=max_samples\n",
        "    )\n",
        "\n",
        "    if len(dataset) == 0:\n",
        "        raise ValueError(\"Dataset est√° vazio! Verifique se as imagens foram carregadas corretamente.\")\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "    print(f\"‚úì DataLoader criado com {len(dataloader)} batches\\n\")\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# 2. MODELO CNN (REMOVIDO SIGMOID FINAL)\n",
        "# =====================================================================\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    CNN sem Sigmoid final ‚Äî vamos usar BCEWithLogitsLoss nos logits.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_channels=3, num_classes=1):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((4, 4))\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 4 * 4, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)  # logits (sem Sigmoid)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.fc(x)\n",
        "        return x  # logits\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# 3. TREINAMENTO COM LTN (AJUSTADO)\n",
        "# =====================================================================\n",
        "\n",
        "def train_ltn_classifier(dogs_dir='dogs', cats_dir='cats', n_epochs=5,\n",
        "                         batch_size=64, image_size=96, learning_rate=0.001,\n",
        "                         max_samples=500, device=None):\n",
        "    \"\"\"\n",
        "    Treinamento com BCEWithLogits + LTN fuzzy. √âpocas padr√£o reduzidas para 10.\n",
        "    \"\"\"\n",
        "    device = device or (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
        "    print(f\"üñ•Ô∏è  Usando device: {device}\\n\")\n",
        "\n",
        "    # DataLoader\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ETAPA 1: Carregando Dataset\")\n",
        "    print(\"=\" * 60)\n",
        "    train_dataloader = create_dataloader(\n",
        "        dogs_dir=dogs_dir,\n",
        "        cats_dir=cats_dir,\n",
        "        batch_size=batch_size,\n",
        "        image_size=image_size,\n",
        "        num_workers=0,\n",
        "        augmentation=True,\n",
        "        max_samples=max_samples\n",
        "    )\n",
        "\n",
        "    # Modelo\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ETAPA 2: Criando Modelo CNN\")\n",
        "    print(\"=\" * 60)\n",
        "    model = CNNModel(input_channels=3, num_classes=1)\n",
        "    model = model.to(device)\n",
        "    print(f\"‚úì Modelo criado com {sum(p.numel() for p in model.parameters())} par√¢metros\\n\")\n",
        "\n",
        "    # Otimizador e scheduler\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "\n",
        "    # BCEWithLogitsLoss com pos_weight > 1 para priorizar c√£es (classe positiva)\n",
        "    pos_weight = torch.tensor([1.5]).to(device)\n",
        "    bce_loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ETAPA 3: Iniciando Treinamento\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        correct_dogs = 0\n",
        "        correct_cats = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for i, (dog_imgs, cat_imgs) in enumerate(train_dataloader):\n",
        "            dog_imgs = dog_imgs.to(device)\n",
        "            cat_imgs = cat_imgs.to(device)\n",
        "\n",
        "            # Concatena c√£es + gatos para formar um batch √∫nico\n",
        "            inputs = torch.cat([dog_imgs, cat_imgs], dim=0)\n",
        "            labels = torch.cat([\n",
        "                torch.ones(dog_imgs.size(0), 1, device=device),\n",
        "                torch.zeros(cat_imgs.size(0), 1, device=device)\n",
        "            ], dim=0)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits = model(inputs)\n",
        "\n",
        "            # LTN fuzzy\n",
        "            probs = torch.sigmoid(logits)\n",
        "            dogs_probs = probs[:dog_imgs.size(0)]\n",
        "            cats_probs = probs[dog_imgs.size(0):]\n",
        "            phi1 = torch.mean(dogs_probs)\n",
        "            phi2 = torch.mean(1.0 - cats_probs)\n",
        "            sat_agg = (phi1 + phi2) / 2.0\n",
        "            ltn_loss = 1.0 - sat_agg\n",
        "\n",
        "            # BCEWithLogitsLoss\n",
        "            bce_total = bce_loss_fn(logits, labels)\n",
        "\n",
        "            # Combinar losses\n",
        "            loss = 0.4 * ltn_loss + 0.6 * bce_total\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # M√©tricas de acur√°cia\n",
        "            with torch.no_grad():\n",
        "                preds = (probs > 0.5).float()\n",
        "                correct_dogs += preds[:dog_imgs.size(0)].sum().item()\n",
        "                correct_cats += (1 - preds[dog_imgs.size(0):]).sum().item()\n",
        "                total_samples += inputs.size(0)\n",
        "\n",
        "            if (i + 1) % 5 == 0 or (i + 1) == len(train_dataloader):\n",
        "                batch_acc = (correct_dogs + correct_cats) / total_samples * 100\n",
        "                print(f\"Epoch [{epoch+1}/{n_epochs}], Step [{i+1}/{len(train_dataloader)}], \"\n",
        "                      f\"Loss: {loss.item():.4f}, Acc(batch): {batch_acc:.2f}%\")\n",
        "\n",
        "        epoch_loss = epoch_loss / len(train_dataloader)\n",
        "        epoch_acc = (correct_dogs + correct_cats) / total_samples * 100\n",
        "\n",
        "        scheduler.step(epoch_loss)\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Epoch [{epoch+1}/{n_epochs}] Completado\")\n",
        "        print(f\"Loss M√©dio: {epoch_loss:.4f}\")\n",
        "        print(f\"Acur√°cia: {epoch_acc:.2f}%\")\n",
        "        print(f\"C√£es corretos (aprx): {int(correct_dogs)}/{total_samples//2}\")\n",
        "        print(f\"Gatos corretos (aprx): {int(correct_cats)}/{total_samples//2}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        if epoch_loss < best_loss:\n",
        "            best_loss = epoch_loss\n",
        "            print(f\"üíæ Novo melhor modelo (na mem√≥ria). Loss: {best_loss:.4f}\\n\")\n",
        "\n",
        "    print(\"üéâ Treinamento conclu√≠do!\\n\")\n",
        "    return model, train_dataloader\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# 4. AVALIA√á√ÉO E TESTES\n",
        "# =====================================================================\n",
        "\n",
        "def evaluate_model(model, dataloader, device, num_samples=5):\n",
        "    model.eval()\n",
        "    print(\"=\" * 60)\n",
        "    print(\"AVALIA√á√ÉO DO MODELO\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        dog_imgs, cat_imgs = next(iter(dataloader))\n",
        "        dog_imgs = dog_imgs[:num_samples].to(device)\n",
        "        cat_imgs = cat_imgs[:num_samples].to(device)\n",
        "\n",
        "        inputs = torch.cat([dog_imgs, cat_imgs], dim=0)\n",
        "        logits = model(inputs)\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        dog_probs = probs[:num_samples]\n",
        "        cat_probs = probs[num_samples:]\n",
        "\n",
        "        print(f\"\\nPredi√ß√µes para {num_samples} imagens de C√ÉES:\")\n",
        "        for i, p in enumerate(dog_probs):\n",
        "            print(f\"  Imagem {i+1}: {p.item():.4f} (esperado: ~1.0)\")\n",
        "\n",
        "        print(f\"\\nPredi√ß√µes para {num_samples} imagens de GATOS:\")\n",
        "        for i, p in enumerate(cat_probs):\n",
        "            print(f\"  Imagem {i+1}: {p.item():.4f} (esperado: ~0.0)\")\n",
        "\n",
        "        dog_correct = (dog_probs > 0.5).sum().item()\n",
        "        cat_correct = (cat_probs <= 0.5).sum().item()\n",
        "        accuracy = (dog_correct + cat_correct) / (2 * num_samples) * 100\n",
        "\n",
        "        print(f\"\\n‚úì Acur√°cia nas amostras: {accuracy:.2f}%\")\n",
        "        print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# 5. EXECU√á√ÉO PRINCIPAL\n",
        "# =====================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"CLASSIFICADOR BIN√ÅRIO: C√ÉES vs GATOS (DATASET LOCAL)\")\n",
        "    print(\"Usando BCEWithLogits + L√≥gica fuzzy (LTN simplificada)\")\n",
        "    print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "    print(f\"üìÇ Pasta de c√£es: {pathdog}\")\n",
        "    print(f\"üìÇ Pasta de gatos: {pathcat}\\n\")\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Usando as vari√°veis pathdog e pathcat definidas no in√≠cio\n",
        "    model, dataloader = train_ltn_classifier(\n",
        "        dogs_dir=pathdog,      # <- Usando a vari√°vel pathdog\n",
        "        cats_dir=pathcat,      # <- Usando a vari√°vel pathcat\n",
        "        n_epochs=5,            # <- Reduzido para 5 √©pocas\n",
        "        batch_size=64,         # <- Aumentado para processar mais imagens por vez\n",
        "        image_size=96,         # <- Reduzido para 96x96 (mais r√°pido)\n",
        "        learning_rate=0.001,   # <- Learning rate um pouco maior\n",
        "        max_samples=500,       # <- APENAS 500 IMAGENS DE CADA (muito mais r√°pido!)\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Avalia√ß√£o r√°pida\n",
        "    evaluate_model(model, dataloader, device, num_samples=5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}